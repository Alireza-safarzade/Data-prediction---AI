#1 install Lab
!pip install optuna openpyxl lightgbm scikit-learn matplotlib seaborn --quiet
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 2. import
import pandas as pd
import numpy as np
import optuna
from lightgbm import LGBMClassifier, early_stopping
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 3. Upload training file
print("â¬†ï¸ Please upload the training file (train.xlsx):")
uploaded_train = files.upload()
train_path = list(uploaded_train.keys())[0]
df_train = pd.read_excel(train_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 4. Data preparation
X = df_train.drop(columns=["Result"])
y = df_train["Result"]
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 5. Training/Accreditation Division
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 6. Optuna objective
def objective(trial):
    param = {
        'objective': 'multiclass',
        'num_class': len(np.unique(y)),
        'boosting_type': 'gbdt',
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'num_leaves': trial.suggest_int('num_leaves', 15, 200),
        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),
        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),
        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),
        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),
        'verbosity': -1,
        'n_estimators': 1000
    }

    model = LGBMClassifier(**param)
    model.fit(
        X_train, y_train,
        eval_set=[(X_valid, y_valid)],
        eval_metric='multi_logloss',
        callbacks=[early_stopping(20)]
    )
    preds = model.predict(X_valid)
    return accuracy_score(y_valid, preds)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 7.  Optuna
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 8. Teaching the final model
best_params = study.best_params
best_params.update({
    'objective': 'multiclass',
    'num_class': len(np.unique(y)),
    'n_estimators': 100
})
model = LGBMClassifier(**best_params)
model.fit(X, y)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“Œ 9. Prediction on validation data for reporting
valid_preds = model.predict(X_valid)
print("âœ… Accuracy:", accuracy_score(y_valid, valid_preds))
print("\nğŸ“„ Classification Report:")
print(classification_report(y_valid, valid_preds))
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ”· 10. Confusion Matrix
cm = confusion_matrix(y_valid, valid_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y), yticklabels=np.unique(y))
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ”¶ 11.The importance of features
import lightgbm as lgb
lgb.plot_importance(model, max_num_features=20, importance_type='gain', figsize=(10, 6))
plt.title("Feature Importance")
plt.show()
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“¥ 12. Upload test file
print("â¬†ï¸ Please Upload Test File (test.xlsx) :")
uploaded_test = files.upload()
test_path = list(uploaded_test.keys())[0]
df_test = pd.read_excel(test_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“¤ 13. Prediction on test and output
feature_columns = X.columns.tolist()
model.fit(X[feature_columns], y)
eature_columns = [col for col in X.columns if col in df_test.columns]
test_preds = model.predict(df_test[feature_columns])
df_test["Result"] = test_preds
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# ğŸ“¦ 14.Download the output file
output_path = "predicted_result.xlsx"
df_test.to_excel(output_path, index=False)
files.download(output_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
