# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
!pip install openpyxl scipy seaborn matplotlib xgboost scikit-learn pandas --quiet

# Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
from google.colab import files
uploaded = files.upload()

# Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
import pandas as pd
import io
file_name = list(uploaded.keys())[0]
df = pd.read_excel(io.BytesIO(uploaded[file_name]))

# Ø³ØªÙˆÙ† Ù‡Ø¯Ù
target_col = "Result"

# ğŸ” Ù†Ù…Ø§ÛŒØ´ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
print("Ù…Ù‚Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø³ØªÙˆÙ† Ù‡Ø¯Ù:", df[target_col].unique())

# ÙÙ‚Ø· Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ø¨Ø§ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± (-1, 0, 1)
df = df[df[target_col].isin([-1, 0, 1])]

# Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† X Ùˆ y
X = df.drop(columns=[target_col])
y = df[target_col].map({-1: 0, 0: 1, 1: 2})  # Ø¨Ø§Ø²Ù†Ú¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ XGBoost

# ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯
from scipy.stats import f_oneway, kruskal
results = []
for col in X.columns:
    group_data = [X[y == label][col] for label in sorted(y.unique())]
    try:
        f_stat, p_value = f_oneway(*group_data)
    except:
        f_stat, p_value = kruskal(*group_data)
    results.append({"Feature": col, "P-value": p_value})

results_df = pd.DataFrame(results).sort_values(by="P-value")
useful_features = results_df[results_df["P-value"] < 0.05]["Feature"].tolist()

print("\nâœ… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ (P < 0.05):")
print(useful_features)

# ÙÙ‚Ø· Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯
X_selected = X[useful_features]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, random_state=42, stratify=y
)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ XGBoost
from xgboost import XGBClassifier
model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric="mlogloss")
model.fit(X_train, y_train)

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
y_pred = model.predict(X_test)

print("\nğŸ¯ Ø¯Ù‚Øª Ù…Ø¯Ù„:", accuracy_score(y_test, y_pred))
print("\nğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:\n", classification_report(y_test, y_pred))
print("\nğŸ§© Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ:\n", confusion_matrix(y_test, y_pred))

# Ù†Ù…Ø§ÛŒØ´ Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
import matplotlib.pyplot as plt
import seaborn as sns

importances = model.feature_importances_
feat_imp = pd.DataFrame({"Feature": useful_features, "Importance": importances})
feat_imp = feat_imp.sort_values(by="Importance", ascending=False)

plt.figure(figsize=(10, 5))
sns.barplot(data=feat_imp, x="Importance", y="Feature", palette="viridis")
plt.title("ğŸ” Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (XGBoost)")
plt.tight_layout()
plt.show()