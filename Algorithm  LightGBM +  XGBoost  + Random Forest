#1 install Lab
!pip install lightgbm xgboost openpyxl scikit-learn matplotlib seaborn --quiet
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 2. imports
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from google.colab import files
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 3. Upload training file
print("⬆️ Please upload the training file (train.xlsx):")
uploaded_train = files.upload()
train_path = list(uploaded_train.keys())[0]
df_train = pd.read_excel(train_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 4. Data preparation
if 'Profit' in df_train.columns:
    df_train.drop(columns=['Profit'], inplace=True)

X = df_train.drop(columns=['Result'])
y = df_train['Result']
feature_columns = X.columns.tolist()
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 5. Training/Accreditation Division
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 6. Definition of models
model_lgb = LGBMClassifier(random_state=42)
model_xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')
model_rf = RandomForestClassifier(random_state=42)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 7. Combining Models with Voting
ensemble_model = VotingClassifier(
    estimators=[
        ('lgb', model_lgb),
        ('xgb', model_xgb),
        ('rf', model_rf)
    ],
    voting='hard'  # یا 'soft' برای میانگین احتمالات
)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 8. Combined model training
ensemble_model.fit(X_train, y_train)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 9. Mixed model evaluation
valid_preds = ensemble_model.predict(X_valid)
print("✅ گزارش طبقه‌بندی مدل ترکیبی:")
print(classification_report(y_valid, valid_preds))
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 10. Matrix
ConfusionMatrixDisplay.from_estimator(ensemble_model, X_valid, y_valid, display_labels=np.unique(y), cmap='Blues')
plt.title("Confusion Matrix - Voting Ensemble")
plt.grid(False)
plt.show()
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 11. Get the test file
print(Please upload the training file (train.xlsx):")
uploaded_test = files.upload()
test_path = list(uploaded_test.keys())[0]
df_test = pd.read_excel(test_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 12. Prediction on the test file
df_test_input = df_test[feature_columns]
test_preds = ensemble_model.predict(df_test_input)
df_test['Result'] = test_preds
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 13.Save the output
output_path = "predicted_result_ensemble.xlsx"
df_test.to_excel(output_path, index=False)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
# 📌 14. Download the final file
files.download(output_path)
#<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>
