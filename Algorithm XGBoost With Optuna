# ğŸ“Œ 1. Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
!pip install xgboost openpyxl optuna scikit-learn matplotlib seaborn

# ğŸ“Œ 2. importÙ‡Ø§
import pandas as pd
import numpy as np
import xgboost as xgb
import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
# ğŸ“Œ 3. Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´
print("âœ… Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´ (Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ† Result Ùˆ Ø¨Ø¯ÙˆÙ† Profit Ø¯Ø± ØªØ³Øª) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯")
uploaded = files.upload()
file_path = next(iter(uploaded))
train_df = pd.read_excel(file_path)

# Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¹Ø¯Ø¯ÛŒ Ù…Ø«Ù„ Time
train_df = train_df.select_dtypes(include=[np.number])

# Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù‡Ø¯Ù
X = train_df.drop(columns=["Result"], errors='ignore')
y = train_df["Result"]

# Ù†Ú¯Ø§Ø´Øª Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ XGBoost (Ø¨Ù‡ 0 Ùˆ 1 Ùˆ 2)
label_map = {-1: 0, 0: 1, 1: 2}
y = y.map(label_map)

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)


# ğŸ“Œ 4. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´: Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ùˆ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
# Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ù†Ù…ÛŒâ€ŒØªÙˆÙ†Ù‡ Ø¨Ø§Ù‡Ø§Ø´ÙˆÙ† Ú©Ø§Ø± Ú©Ù†Ù‡
if 'Time' in train_df.columns:
    train_df = train_df.drop(columns=['Time'])

# Ø¬Ø¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ø¯Ù Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
y = train_df["Result"]
X = train_df.drop(columns=["Result", "Profit"], errors='ignore')

# Ù†Ú¯Ø§Ø´Øª Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¨Ù‡ Ø§Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¨Ù„ ÙÙ‡Ù… Ø¨Ø±Ø§ÛŒ XGBoost
label_map = {-1: 0, 0: 1, 1: 2}
y_mapped = y.map(label_map)

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
X_train, X_valid, y_train, y_valid = train_test_split(X, y_mapped, test_size=0.2, random_state=42)


# ğŸ“Œ 5. ØªØ¹Ø±ÛŒÙ ØªØ§Ø¨Ø¹ Optuna Ø¨Ø±Ø§ÛŒ XGBoost
def objective(trial):
    params = {
        "objective": "multi:softprob",
        "num_class": 3,
        "eval_metric": "mlogloss",
        "booster": "gbtree",
        "tree_method": "auto",
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
        "verbosity": 0
    }

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dvalid = xgb.DMatrix(X_valid, label=y_valid)

    model = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=[(dvalid, "valid")],
        early_stopping_rounds=30,
        verbose_eval=False
    )

    preds = model.predict(dvalid)
    pred_labels = np.argmax(preds, axis=1)
    acc = accuracy_score(y_valid, pred_labels)
    return acc


# ğŸ“Œ 6. Ø§Ø¬Ø±Ø§ÛŒ Optuna
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)

# ğŸ“Œ 7. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
best_params = study.best_params
best_params.update({
    "objective": "multi:softprob",
    "num_class": 3,
    "eval_metric": "mlogloss",
    "verbosity": 0
})

dtrain_final = xgb.DMatrix(X, label=y_mapped)
final_model = xgb.train(best_params, dtrain_final, num_boost_round=study.best_trial.number)


# ğŸ“Œ 8. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØªØ³Øª Ø§Ø² Ú©Ø§Ø±Ø¨Ø±
uploaded_test = files.upload()

# ÙØ±Ø¶: ÙØ§ÛŒÙ„ ØªØ³Øª Ù…Ø«Ù„Ø§Ù‹ Ø§Ø³Ù…Ø´ Ù‡Ø³Øª test.xlsx
df_test = pd.read_excel(next(iter(uploaded_test)))
if 'Time' in df_test.columns:
    df_test = df_test.drop(columns=['Time'])

X_test = df_test.copy()

# ğŸ“Œ 9. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª
dtest = xgb.DMatrix(X_test)
pred_probs = final_model.predict(dtest)
pred_labels = np.argmax(pred_probs, axis=1)

# Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¨Ù‡ Ø­Ø§Ù„Øª Ø§ØµÙ„ÛŒ
reverse_map = {0: -1, 1: 0, 2: 1}
pred_result = pd.Series(pred_labels).map(reverse_map)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ù‡ DataFrame Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒ
df_test["Result"] = pred_result
df_test.to_excel("predicted_test.xlsx", index=False)

# ğŸ“¤ Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
files.download("predicted_test.xlsx")
