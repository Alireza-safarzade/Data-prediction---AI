# ğŸ“Œ 1. Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
!pip install xgboost openpyxl optuna scikit-learn matplotlib seaborn

# ğŸ“Œ 2. importÙ‡Ø§
import pandas as pd
import numpy as np
import xgboost as xgb
import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

# ğŸ“Œ 3. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´
print("â¬†ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø¢Ù…ÙˆØ²Ø´ (train.xlsx) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:")
uploaded_train = files.upload()
train_path = list(uploaded_train.keys())[0]
df_train = pd.read_excel(train_path)

# ğŸ“Œ 4. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡
X = df_train.drop(columns=["Result", "Profit"], errors="ignore")  # Ø­Ø°Ù Profit ÙÙ‚Ø· Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù‡
y = df_train["Result"]

# Ø°Ø®ÛŒØ±Ù‡ Ù†Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± ØªØ³Øª
feature_columns = X.columns.tolist()

# ğŸ“Œ 5. ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´/Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ“Œ 6. ØªØ¹Ø±ÛŒÙ objective Ø¨Ø±Ø§ÛŒ Optuna
def objective(trial):
    param = {
        'objective': 'multi:softprob',
        'num_class': len(np.unique(y)),
        'eval_metric': 'mlogloss',
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'verbosity': 0,
        'tree_method': 'auto'
    }

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dvalid = xgb.DMatrix(X_valid, label=y_valid)
    model = xgb.train(param, dtrain, num_boost_round=300, evals=[(dvalid, "eval")], early_stopping_rounds=20, verbose_eval=False)
    preds = model.predict(dvalid)
    pred_labels = np.argmax(preds, axis=1)
    return accuracy_score(y_valid, pred_labels)

# ğŸ“Œ 7. Ø§Ø¬Ø±Ø§ÛŒ Optuna Ø¨Ø±Ø§ÛŒ XGBoost
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)

# ğŸ“Œ 8. Ø¢Ù…ÙˆØ²Ø´ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ø¨Ø§ Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§
best_params = study.best_params
best_params.update({
    'objective': 'multi:softprob',
    'num_class': len(np.unique(y)),
    'eval_metric': 'mlogloss',
    'verbosity': 0,
    'tree_method': 'auto'
})
dtrain_full = xgb.DMatrix(X, label=y)
final_model = xgb.train(best_params, dtrain_full, num_boost_round=300)

# ğŸ“Œ 9. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ validation set
dvalid = xgb.DMatrix(X_valid)
valid_preds = final_model.predict(dvalid)
valid_pred_labels = np.argmax(valid_preds, axis=1)

print("âœ… Accuracy:", accuracy_score(y_valid, valid_pred_labels))
print("\nğŸ“„ Classification Report:")
print(classification_report(y_valid, valid_pred_labels))

# ğŸ“Œ 10. Ù…Ø§ØªØ±ÛŒØ³ Ø³Ø±Ø¯Ø±Ú¯Ù…ÛŒ
cm = confusion_matrix(y_valid, valid_pred_labels)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# ğŸ“Œ 11. Ø§Ù‡Ù…ÛŒØª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
xgb.plot_importance(final_model, max_num_features=20, importance_type='gain', height=0.5)
plt.title("Feature Importance (Gain)")
plt.show()

# ğŸ“Œ 12. Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØªØ³Øª
print("â¬†ï¸ Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ ØªØ³Øª (test.xlsx) Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:")
uploaded_test = files.upload()
test_path = list(uploaded_test.keys())[0]
df_test = pd.read_excel(test_path)

# ğŸ“Œ 13. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ ØªØ³Øª
df_test_for_pred = df_test[feature_columns]
dtest = xgb.DMatrix(df_test_for_pred)
test_preds = final_model.predict(dtest)
test_pred_labels = np.argmax(test_preds, axis=1)
df_test["Result"] = test_pred_labels

# ğŸ“Œ 14. Ø®Ø±ÙˆØ¬ÛŒ ÙØ§ÛŒÙ„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡
output_path = "xgb_predicted_result.xlsx"
df_test.to_excel(output_path, index=False)

# ğŸ“¦ 15. Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
files.download(output_path)
