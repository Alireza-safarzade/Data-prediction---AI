# 📌 1. نصب کتابخانه‌ها
!pip install xgboost openpyxl optuna scikit-learn matplotlib seaborn

# 📌 2. importها
import pandas as pd
import numpy as np
import xgboost as xgb
import optuna
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
# 📌 3. آپلود و آماده‌سازی فایل آموزش
print("✅ لطفاً فایل آموزش (شامل ستون Result و بدون Profit در تست) را آپلود کنید")
uploaded = files.upload()
file_path = next(iter(uploaded))
train_df = pd.read_excel(file_path)

# حذف ستون‌های غیرعددی مثل Time
train_df = train_df.select_dtypes(include=[np.number])

# جداسازی ویژگی‌ها و هدف
X = train_df.drop(columns=["Result"], errors='ignore')
y = train_df["Result"]

# نگاشت کلاس‌ها برای XGBoost (به 0 و 1 و 2)
label_map = {-1: 0, 0: 1, 1: 2}
y = y.map(label_map)

# تقسیم داده‌ها
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)


# 📌 4. پیش‌پردازش: حذف ستون‌های اضافی و آماده‌سازی داده‌ها
# حذف ستون‌هایی که مدل نمی‌تونه باهاشون کار کنه
if 'Time' in train_df.columns:
    train_df = train_df.drop(columns=['Time'])

# جدا کردن هدف و ویژگی‌ها
y = train_df["Result"]
X = train_df.drop(columns=["Result", "Profit"], errors='ignore')

# نگاشت کلاس‌ها به اعداد قابل فهم برای XGBoost
label_map = {-1: 0, 0: 1, 1: 2}
y_mapped = y.map(label_map)

# تقسیم داده‌ها برای آموزش و اعتبارسنجی
X_train, X_valid, y_train, y_valid = train_test_split(X, y_mapped, test_size=0.2, random_state=42)


# 📌 5. تعریف تابع Optuna برای XGBoost
def objective(trial):
    params = {
        "objective": "multi:softprob",
        "num_class": 3,
        "eval_metric": "mlogloss",
        "booster": "gbtree",
        "tree_method": "auto",
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "max_depth": trial.suggest_int("max_depth", 3, 10),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "min_child_weight": trial.suggest_int("min_child_weight", 1, 10),
        "verbosity": 0
    }

    dtrain = xgb.DMatrix(X_train, label=y_train)
    dvalid = xgb.DMatrix(X_valid, label=y_valid)

    model = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=[(dvalid, "valid")],
        early_stopping_rounds=30,
        verbose_eval=False
    )

    preds = model.predict(dvalid)
    pred_labels = np.argmax(preds, axis=1)
    acc = accuracy_score(y_valid, pred_labels)
    return acc


# 📌 6. اجرای Optuna
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=50)

# 📌 7. آموزش مدل نهایی با بهترین پارامترها
best_params = study.best_params
best_params.update({
    "objective": "multi:softprob",
    "num_class": 3,
    "eval_metric": "mlogloss",
    "verbosity": 0
})

dtrain_final = xgb.DMatrix(X, label=y_mapped)
final_model = xgb.train(best_params, dtrain_final, num_boost_round=study.best_trial.number)


# 📌 8. آپلود فایل تست از کاربر
uploaded_test = files.upload()

# فرض: فایل تست مثلاً اسمش هست test.xlsx
df_test = pd.read_excel(next(iter(uploaded_test)))
if 'Time' in df_test.columns:
    df_test = df_test.drop(columns=['Time'])

X_test = df_test.copy()

# 📌 9. پیش‌بینی روی داده تست
dtest = xgb.DMatrix(X_test)
pred_probs = final_model.predict(dtest)
pred_labels = np.argmax(pred_probs, axis=1)

# بازگردانی کلاس‌ها به حالت اصلی
reverse_map = {0: -1, 1: 0, 2: 1}
pred_result = pd.Series(pred_labels).map(reverse_map)

# اضافه کردن به DataFrame و ذخیره خروجی
df_test["Result"] = pred_result
df_test.to_excel("predicted_test.xlsx", index=False)

# 📤 دانلود فایل
files.download("predicted_test.xlsx")
